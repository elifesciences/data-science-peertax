{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization of sentences (preparation for LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.! This notebook requires a dataframe of \"sentencized\" texts.\n",
    "\n",
    "Run \"Text_Sentencizer.ipynb\" and create a \"sentencized.pkl\" before running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130846 entries, 0 to 130845\n",
      "Data columns (total 3 columns):\n",
      "manuscript_ID    130846 non-null object\n",
      "review_ID        130846 non-null object\n",
      "sentences        130846 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "flatten_df = pd.read_pickle('../pickles/f1000_sentencized.pkl')\n",
    "flatten_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove standard sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126818 entries, 0 to 126817\n",
      "Data columns (total 3 columns):\n",
      "manuscript_ID    126818 non-null object\n",
      "review_ID        126818 non-null object\n",
      "sentences        126818 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "std_sentence = 'I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.'\n",
    "flatten_df = flatten_df[flatten_df.sentences != std_sentence]\n",
    "flatten_df.reset_index(drop=True,inplace=True)\n",
    "flatten_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test preprocessing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84dd5c28007a43e9b8f44a84df404d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from peertax.tokenizer_LDA import custom_tokenizer as ct\n",
    "from random import randint\n",
    "num = randint(0,len(flatten_df))\n",
    "sent_test = [flatten_df.loc[num,'sentences']]\n",
    "sent_after = ct(sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Please explain.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None]\n"
     ]
    }
   ],
   "source": [
    "print(sent_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa3d3aabe4342e3a5253be05046c49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=126818), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to clean up everything: 8.89 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "txt = ct(flatten_df['sentences'])\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the results in a DataFrame to remove missing values.\n",
    "\n",
    "Don't remove duplicates because they are still reviews!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 114523 entries, 1 to 126817\n",
      "Data columns (total 1 columns):\n",
      "token    114523 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'token': txt})\n",
    "df_clean = df_clean.dropna()\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge with initial dataset to retain indexing. Assign a provisional 'token' column (will update after creating bigram and trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114523 entries, 0 to 114522\n",
      "Data columns (total 4 columns):\n",
      "manuscript_ID    114523 non-null object\n",
      "review_ID        114523 non-null object\n",
      "sentences        114523 non-null object\n",
      "token            114523 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = pd.concat([flatten_df, df_clean], axis=1, join='inner').reset_index(drop=True)\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manuscript_ID</th>\n",
       "      <th>review_ID</th>\n",
       "      <th>sentences</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r101</td>\n",
       "      <td>However, I am sure there are some sections whe...</td>\n",
       "      <td>sure section reader like information adjustmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>This paper has a number of serious flaws.</td>\n",
       "      <td>paper number flaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>a) The literature is quoted selectively and is...</td>\n",
       "      <td>literature quote selectively issue oversimplify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>The paper states that blood exposure is import...</td>\n",
       "      <td>paper state blood exposure important state pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>For example it doesn t reference articles such...</td>\n",
       "      <td>example doesn reference article unsafe injecti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   manuscript_ID                      review_ID  \\\n",
       "0  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r101   \n",
       "1  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "2  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "3  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "4  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  However, I am sure there are some sections whe...   \n",
       "1          This paper has a number of serious flaws.   \n",
       "2  a) The literature is quoted selectively and is...   \n",
       "3  The paper states that blood exposure is import...   \n",
       "4  For example it doesn t reference articles such...   \n",
       "\n",
       "                                               token  \n",
       "0  sure section reader like information adjustmen...  \n",
       "1                                  paper number flaw  \n",
       "2    literature quote selectively issue oversimplify  \n",
       "3  paper state blood exposure important state pre...  \n",
       "4  example doesn reference article unsafe injecti...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df_cleaned['token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:14:22: collecting all words and their counts\n",
      "INFO - 13:14:22: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 13:14:25: PROGRESS: at sentence #100000, processed 1017374 words and 569315 word types\n",
      "INFO - 13:14:26: collected 632062 word types from a corpus of 1161874 words (unigram + bigrams) and 114523 sentences\n",
      "INFO - 13:14:26: using 632062 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "phrases_bi = Phrases(sent, min_count=30, progress_per=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:14:26: source_vocab length 632062\n",
      "INFO - 13:14:41: Phraser built with 387 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:14:41: collecting all words and their counts\n",
      "INFO - 13:14:41: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 13:14:53: PROGRESS: at sentence #100000, processed 973137 words and 580825 word types\n",
      "INFO - 13:14:55: collected 645470 word types from a corpus of 1110962 words (unigram + bigrams) and 114523 sentences\n",
      "INFO - 13:14:55: using 645470 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "phrases_tri = Phrases(phrases_bi[sent], min_count=30, progress_per=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:14:55: source_vocab length 645470\n",
      "INFO - 13:15:12: Phraser built with 457 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "trigram = Phraser(phrases_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the corpus based on the bigrams & trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = trigram[bigram[sent]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run figure_conv() to convert bigrams (like fig_a etc.) found during last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_conv(text):\n",
    "    if text in ['figure','figure_a','figure_b','figure_c',\n",
    "                'fig','fig_a','fig_b','fig_c','figure_figure_supplement']:\n",
    "        return 'figure'\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "def figure_conv_array(doc):\n",
    "    return [figure_conv(word) for word in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [figure_conv_array(r) for r in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do sanity check of the effectiveness of the cleaning and addition of bigrams & trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36621"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['author',\n",
       " 'study',\n",
       " 'datum',\n",
       " 'result',\n",
       " 'paper',\n",
       " 'provide',\n",
       " 'analysis',\n",
       " 'figure',\n",
       " 'use',\n",
       " 'method',\n",
       " 'article',\n",
       " 'present',\n",
       " 'need',\n",
       " 'patient',\n",
       " 'include',\n",
       " 'different',\n",
       " 'describe',\n",
       " 'manuscript',\n",
       " 'work',\n",
       " 'case']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'token' column with new, actual 'tokens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manuscript_ID</th>\n",
       "      <th>review_ID</th>\n",
       "      <th>sentences</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r101</td>\n",
       "      <td>However, I am sure there are some sections whe...</td>\n",
       "      <td>[sure, section, reader, like, information, adj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>This paper has a number of serious flaws.</td>\n",
       "      <td>[paper, number, flaw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>a) The literature is quoted selectively and is...</td>\n",
       "      <td>[literature, quote, selectively, issue, oversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>The paper states that blood exposure is import...</td>\n",
       "      <td>[paper, state, blood, exposure, important, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>For example it doesn t reference articles such...</td>\n",
       "      <td>[example, doesn, reference, article, unsafe, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   manuscript_ID                      review_ID  \\\n",
       "0  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r101   \n",
       "1  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "2  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "3  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "4  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  However, I am sure there are some sections whe...   \n",
       "1          This paper has a number of serious flaws.   \n",
       "2  a) The literature is quoted selectively and is...   \n",
       "3  The paper states that blood exposure is import...   \n",
       "4  For example it doesn t reference articles such...   \n",
       "\n",
       "                                               token  \n",
       "0  [sure, section, reader, like, information, adj...  \n",
       "1                              [paper, number, flaw]  \n",
       "2  [literature, quote, selectively, issue, oversi...  \n",
       "3  [paper, state, blood, exposure, important, sta...  \n",
       "4  [example, doesn, reference, article, unsafe, i...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['token'] = [r for r in sentences]\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataframe with tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE TO PICKLE. NEED TO PUT THIS INTO A FUNCTION THAT CHECKS FOR EXISTENCE\n",
    "path_save_pickle = \"../pickles/f1000_tokenized_LDA_sentence_0.pkl\"\n",
    "df_cleaned.to_pickle(path_save_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
