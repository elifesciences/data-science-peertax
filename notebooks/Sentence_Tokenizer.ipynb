{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization of sentences (preparation for LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.! This notebook requires a dataframe of \"sentencized\" texts.\n",
    "\n",
    "Run \"Text_Sentencizer.ipynb\" and create a \"sentencized.pkl\" before running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 132419 entries, 0 to 132418\n",
      "Data columns (total 3 columns):\n",
      "manuscript_ID    132419 non-null object\n",
      "review_ID        132419 non-null object\n",
      "sentences        132419 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "flatten_df = pd.read_pickle('../pickles/f1000_sentencized.pkl')\n",
    "flatten_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove standard sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125842 entries, 0 to 125841\n",
      "Data columns (total 3 columns):\n",
      "manuscript_ID    125842 non-null object\n",
      "review_ID        125842 non-null object\n",
      "sentences        125842 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "std_sentence = ['I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.',\n",
    "                'I confirm that I have read this submission and believe that I have an appropriate level of expertise to state that I do not consider it to be of an acceptable scientific standard, for reasons outlined above.',\n",
    "                'I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above.']\n",
    "flatten_df = flatten_df[~flatten_df.sentences.isin(std_sentence)]\n",
    "flatten_df.reset_index(drop=True,inplace=True)\n",
    "flatten_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test preprocessing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84fadc7f7479498285d875fb805c254a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from peertax.tokenizer_LDA import custom_tokenizer as ct\n",
    "from random import randint\n",
    "num = randint(0,len(flatten_df))\n",
    "sent_test = [flatten_df.loc[num,'sentences']]\n",
    "sent_after = ct(sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The author seeks to address this in part through an alternative Python implementation, but laments that external library dependencies required to do research in Python and the difficulties in tracking strong versioning available in the bytecode implementation.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author seek address alternative python implementation lament external library dependency require research python difficulty track strong versioning available bytecode implementation']\n"
     ]
    }
   ],
   "source": [
    "print(sent_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36c5c8357a547b6b3f7df74af72b10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125842), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to clean up everything: 7.75 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "txt = ct(flatten_df['sentences'])\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the results in a DataFrame to remove missing values.\n",
    "\n",
    "Don't remove duplicates because they are still reviews!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 112596 entries, 1 to 125841\n",
      "Data columns (total 1 columns):\n",
      "token    112596 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'token': txt})\n",
    "df_clean = df_clean.dropna()\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge with initial dataset to retain indexing. Assign a provisional 'token' column (will update after creating bigram and trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112596 entries, 0 to 112595\n",
      "Data columns (total 4 columns):\n",
      "manuscript_ID    112596 non-null object\n",
      "review_ID        112596 non-null object\n",
      "sentences        112596 non-null object\n",
      "token            112596 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = pd.concat([flatten_df, df_clean], axis=1, join='inner').reset_index(drop=True)\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manuscript_ID</th>\n",
       "      <th>review_ID</th>\n",
       "      <th>sentences</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r101</td>\n",
       "      <td>However, I am sure there are some sections whe...</td>\n",
       "      <td>sure section reader like information adjustmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>This paper has a number of serious flaws.</td>\n",
       "      <td>paper number flaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>a) The literature is quoted selectively and is...</td>\n",
       "      <td>literature quote selectively issue oversimplify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>The paper states that blood exposure is import...</td>\n",
       "      <td>paper state blood exposure important state pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.12688/f1000research.1-1.v1</td>\n",
       "      <td>10.5256/f1000research.50.r100</td>\n",
       "      <td>For example it doesn t reference articles such...</td>\n",
       "      <td>example doesn reference article</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   manuscript_ID                      review_ID  \\\n",
       "0  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r101   \n",
       "1  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "2  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "3  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "4  10.12688/f1000research.1-1.v1  10.5256/f1000research.50.r100   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  However, I am sure there are some sections whe...   \n",
       "1          This paper has a number of serious flaws.   \n",
       "2  a) The literature is quoted selectively and is...   \n",
       "3  The paper states that blood exposure is import...   \n",
       "4  For example it doesn t reference articles such...   \n",
       "\n",
       "                                               token  \n",
       "0  sure section reader like information adjustmen...  \n",
       "1                                  paper number flaw  \n",
       "2    literature quote selectively issue oversimplify  \n",
       "3  paper state blood exposure important state pre...  \n",
       "4                    example doesn reference article  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:02:26: 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df_cleaned['token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:02:27: collecting all words and their counts\n",
      "INFO - 14:02:27: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 14:02:30: PROGRESS: at sentence #100000, processed 999083 words and 582204 word types\n",
      "INFO - 14:02:30: collected 638689 word types from a corpus of 1122171 words (unigram + bigrams) and 112596 sentences\n",
      "INFO - 14:02:30: using 638689 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "phrases_bi = Phrases(sent, min_count=30, progress_per=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:02:30: source_vocab length 638689\n",
      "INFO - 14:02:45: Phraser built with 389 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:02:45: collecting all words and their counts\n",
      "INFO - 14:02:45: PROGRESS: at sentence #0, processed 0 words and 0 word types\n"
     ]
    }
   ],
   "source": [
    "phrases_tri = Phrases(phrases_bi[sent], min_count=30, progress_per=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = Phraser(phrases_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the corpus based on the bigrams & trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = trigram[bigram[sent]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run figure_conv() to convert bigrams (like fig_a etc.) found during last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_conv(text):\n",
    "    if text in ['figure','figure_a','figure_b','figure_c',\n",
    "                'fig','fig_a','fig_b','fig_c','figure_figure_supplement']:\n",
    "        return 'figure'\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "def figure_conv_array(doc):\n",
    "    return [figure_conv(word) for word in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [figure_conv_array(r) for r in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do sanity check of the effectiveness of the cleaning and addition of bigrams & trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'token' column with new, actual 'tokens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['token'] = [r for r in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataframe with tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE TO PICKLE. NEED TO PUT THIS INTO A FUNCTION THAT CHECKS FOR EXISTENCE\n",
    "path_save_pickle = \"../pickles/f1000_tokenized_LDA_sentence_0.pkl\"\n",
    "df_cleaned.to_pickle(path_save_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
