{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA: Query and Human Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import gensim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from operator import itemgetter\n",
    "from peertax.LDA_Diagnostic import LDA_Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load eLife trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pth = './eLife_LDA_Trained_Model/'\n",
    "model_no = 'Model_13'\n",
    "model_pth = base_pth + model_no\n",
    "lda_model = gensim.models.ldamodel.LdaModel.load(model_pth)\n",
    "id2word = gensim.corpora.Dictionary.load(model_pth + '.id2word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import wellcome test corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentence data from tsv\n",
    "path_load_tsv = '../pickles/wellcome_tokenized_LDA_sentence_0.tsv'\n",
    "df_test = pd.read_csv(path_load_tsv,sep='\\t',quoting=csv.QUOTE_NONE)\n",
    "df_test.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "df_test['token'] = df_test['token'].str.split(',')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test Corpus\n",
    "texts_test = df_test['token']\n",
    "corpus_test = [id2word.doc2bow(text) for text in texts_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to assign topics to initial dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_analysis(ldamodel, corpus, texts, index):\n",
    "    # Init dictionary\n",
    "    sent_topics_dict = {}\n",
    "    # Get main topic in each document\n",
    "    for i in tqdm(range(len(corpus))):\n",
    "        row = corpus[i]\n",
    "        top_scor = max(ldamodel.get_document_topics(row),key=itemgetter(1))\n",
    "        topic_num = top_scor[0];\n",
    "        prop_topic = top_scor[1];\n",
    "        # Dictionary entry per row\n",
    "        sent_topics_dict[i] = {'Dominant_Topic': int(topic_num),\n",
    "                           'Perc_Contribution': round(prop_topic,4)}        \n",
    "    # Create database from dictionary\n",
    "    sent_topics_df = pd.DataFrame.from_dict(sent_topics_dict, \"index\")\n",
    "    # Add original text to the end of the output\n",
    "    sent_topics_df['texts'] = pd.Series(texts)\n",
    "    sent_topics_df.set_index(index,inplace=True)\n",
    "    \n",
    "    return sent_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_topic_test = topic_analysis(lda_model, corpus_test, df_test.sentences.values, df_test.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {0: 1, \n",
    "      1: 2, \n",
    "      2: 2,\n",
    "      3: 3,\n",
    "      4: 4,\n",
    "      5: 2,\n",
    "      6: 2,\n",
    "      7: 5,\n",
    "      8: 6,   \n",
    "      9: 4,\n",
    "      10: 4,\n",
    "      11: 0,\n",
    "      12: 6}\n",
    "\n",
    "df_category_test=df_topic_test[['Dominant_Topic','Perc_Contribution','texts']].copy()\n",
    "df_category_test['Dominant_Topic']=df_category_test['Dominant_Topic'].map(di)\n",
    "df_category_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_idx = df_category_test['Perc_Contribution'] <= 0.4\n",
    "df_category_test.loc[_idx,'Dominant_Topic'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df_category_test, col=\"Dominant_Topic\",col_wrap=4)\n",
    "g.map(plt.hist, \"Perc_Contribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Dominant_Topic',data=df_category_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group top reviews under each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_reviews_test = pd.DataFrame()\n",
    "\n",
    "df_topic_test_grpd = df_category_test.groupby('Dominant_Topic')\n",
    "for i, grp in df_topic_test_grpd:\n",
    "    top_reviews_test = pd.concat([top_reviews_test, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(40)], \n",
    "                                            axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Category assignments:\n",
    "- Category 1: Figures\n",
    "- Category 2: Statistics/Analysis/Models/Methods/Techniques\n",
    "- Category 3: Novelty/Impact\n",
    "- Category 4: Clarity of Exposition\n",
    "- Category 5: Previous Literature\n",
    "- Category 6: Main Discussion\n",
    "\n",
    "- Category 0: Uncategorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate top sentences for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top = 2\n",
    "topic2_test = top_reviews_test[top_reviews_test['Dominant_Topic']==num_top].index.tolist()\n",
    "for i in topic2_test:\n",
    "    print(top_reviews_test.loc[i,'texts'])\n",
    "    print(top_reviews_test.loc[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select random samples per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 20       # sample size\n",
    "replace = False  # without replacement\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "df_category_samples = df_category_test.groupby('Dominant_Topic', as_index=False).apply(fn)\n",
    "df_category_samples.drop(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built list of sampled elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = []\n",
    "for i in (range(1,1+len(df_category_samples.groupby(level=0)))):\n",
    "    sampled.extend(df_category_samples.loc[i].index.values.tolist())\n",
    "len(sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_samples.reset_index(level=0, drop=True,inplace=True)\n",
    "df_category_samples['random'] = 0\n",
    "df_category_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract further 80 completely random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "d = []\n",
    "i = 0\n",
    "while i < 80:\n",
    "    num = randint(0,len(df_category_test))\n",
    "    if not num in sampled:\n",
    "        sampled.append(num)\n",
    "        d.append({'index': num,\n",
    "                  'Dominant_Topic': df_category_test.loc[num].Dominant_Topic,\n",
    "                  'Perc_Contribution': df_category_test.loc[num].Perc_Contribution,\n",
    "                  'texts': df_category_test.loc[num].texts})\n",
    "        i+=1\n",
    "        \n",
    "df_category_samples_rand = pd.DataFrame(d)\n",
    "len(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_samples_rand['random'] = 1\n",
    "df_category_samples_rand.set_index('index',inplace=True)\n",
    "df_category_samples_rand.index.name = None\n",
    "df_category_samples_rand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_samples_final = pd.concat([df_category_samples,df_category_samples_rand])\n",
    "df_category_samples_final = df_category_samples_final.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_samples_final.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save_csv = '../pickles/wellcome_sentence_human_valid.csv'\n",
    "df_category_samples_final.to_csv(path_save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
